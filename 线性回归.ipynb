{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 定义数据集",
   "id": "5d654ad475fd1b9f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.638488Z",
     "start_time": "2025-01-20T13:52:04.631488Z"
    }
   },
   "source": [
    "from tensorflow import losses\n",
    "\n",
    "#定义数据特征\n",
    "x_data = [1, 2, 3]\n",
    "#定义标签\n",
    "y_data = [2, 4, 6]"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 初始化参数w",
   "id": "2e3e17d0f8420588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.654517Z",
     "start_time": "2025-01-20T13:52:04.648511Z"
    }
   },
   "cell_type": "code",
   "source": "w = 4",
   "id": "4dd776da90365dfb",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 定义线性回归的模型",
   "id": "388ecc24a3a9b324"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.686207Z",
     "start_time": "2025-01-20T13:52:04.672109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forword(x):\n",
    "    return x * w"
   ],
   "id": "b24107bb7ff6afde",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 定义损失函数",
   "id": "6e6d5b419ef5aab7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.717769Z",
     "start_time": "2025-01-20T13:52:04.704163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cost(xs, ys):\n",
    "    cost = 0\n",
    "    for x, y in zip(xs, ys):\n",
    "        y_pred = forword(x)\n",
    "        cost += (y_pred - y) ** 2\n",
    "    return cost / len(xs)"
   ],
   "id": "67a70d32b897bb63",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 计算梯度的函数",
   "id": "a91555ff8da95ea0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.749293Z",
     "start_time": "2025-01-20T13:52:04.735409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient(xs, ys):\n",
    "    grad = 0\n",
    "    for x, y in zip(xs, ys):\n",
    "        grad += 2 * x * (x * w - y)\n",
    "    return grad / len(xs)"
   ],
   "id": "9e527d1a832c339f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.781004Z",
     "start_time": "2025-01-20T13:52:04.767443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(100):\n",
    "    #计算误差损失\n",
    "    cost_val = cost(x_data, y_data)\n",
    "    #计算梯度\n",
    "    grad_val = gradient(x_data, y_data)\n",
    "\n",
    "    w = w - 0.01 * grad_val\n",
    "    print(\"训练轮次：\", epoch, \"w=\", w, \"loss=\", cost_val)"
   ],
   "id": "95be4ed997db2f00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练轮次： 0 w= 3.8133333333333335 loss= 18.666666666666668\n",
      "训练轮次： 1 w= 3.644088888888889 loss= 15.344829629629634\n",
      "训练轮次： 2 w= 3.4906405925925927 loss= 12.614131947983543\n",
      "训练轮次： 3 w= 3.3515141372839508 loss= 10.369377089329047\n",
      "训练轮次： 4 w= 3.225372817804115 loss= 8.524088828632447\n",
      "训练轮次： 5 w= 3.1110046881423976 loss= 7.007179865528257\n",
      "训练轮次： 6 w= 3.0073109172491073 loss= 5.760213279680468\n",
      "训练轮次： 7 w= 2.9132952316391907 loss= 4.735151325376443\n",
      "训练轮次： 8 w= 2.8280543433528664 loss= 3.892504840629453\n",
      "训练轮次： 9 w= 2.750769271306599 loss= 3.199811979212553\n",
      "训练轮次： 10 w= 2.680697472651316 loss= 2.6303876607784615\n",
      "训练轮次： 11 w= 2.6171657085371933 loss= 2.162295563278151\n",
      "训练轮次： 12 w= 2.5595635757403885 loss= 1.7775030550396742\n",
      "训练轮次： 13 w= 2.507337642004619 loss= 1.461186511378391\n",
      "训练轮次： 14 w= 2.4599861287508547 loss= 1.2011602539757655\n",
      "训练轮次： 15 w= 2.4170540900674418 loss= 0.9874071136682568\n",
      "训练轮次： 16 w= 2.3781290416611474 loss= 0.8116925321959152\n",
      "训练轮次： 17 w= 2.3428369977727734 loss= 0.6672473366886963\n",
      "训练轮次： 18 w= 2.3108388779806477 loss= 0.548506966195294\n",
      "训练轮次： 19 w= 2.2818272493691207 loss= 0.45089710429991725\n",
      "训练轮次： 20 w= 2.255523372761336 loss= 0.37065745960583457\n",
      "训练轮次： 21 w= 2.231674524636945 loss= 0.3046969054608673\n",
      "训练轮次： 22 w= 2.2100515690041633 loss= 0.25047439837352037\n",
      "训练轮次： 23 w= 2.190446755897108 loss= 0.20590108765851722\n",
      "训练轮次： 24 w= 2.1726717253467114 loss= 0.16925984521475257\n",
      "训练轮次： 25 w= 2.156555697647685 loss= 0.13913911542631377\n",
      "训练轮次： 26 w= 2.141943832533901 loss= 0.11437853684111576\n",
      "训练轮次： 27 w= 2.1286957414974035 loss= 0.09402424077392309\n",
      "训练轮次： 28 w= 2.1166841389576456 loss= 0.07729210477131034\n",
      "训练轮次： 29 w= 2.1057936193215987 loss= 0.06353754532667338\n",
      "训练轮次： 30 w= 2.095919548184916 loss= 0.05223068614942892\n",
      "训练轮次： 31 w= 2.0869670570209906 loss= 0.04293594537865921\n",
      "训练轮次： 32 w= 2.0788501316990313 loss= 0.035295255365497165\n",
      "训练轮次： 33 w= 2.0714907860737886 loss= 0.029014268588454725\n",
      "训练轮次： 34 w= 2.0648183127069015 loss= 0.02385101830275833\n",
      "训练轮次： 35 w= 2.058768603520924 loss= 0.019606597090125192\n",
      "训练轮次： 36 w= 2.053283533858971 loss= 0.01611749421239793\n",
      "训练轮次： 37 w= 2.048310404032134 loss= 0.013249296575667239\n",
      "训练轮次： 38 w= 2.0438014329891345 loss= 0.010891510642824056\n",
      "训练轮次： 39 w= 2.039713299243482 loss= 0.008953305815540996\n",
      "训练轮次： 40 w= 2.0360067246474234 loss= 0.007360015305077544\n",
      "训练轮次： 41 w= 2.032646097013664 loss= 0.006050259692565043\n",
      "训练轮次： 42 w= 2.0295991279590555 loss= 0.004973582367719241\n",
      "训练轮次： 43 w= 2.026836542682877 loss= 0.004088505754370499\n",
      "训练轮次： 44 w= 2.024331798699142 loss= 0.0033609334414594523\n",
      "训练轮次： 45 w= 2.0220608308205557 loss= 0.0027628366636993054\n",
      "训练轮次： 46 w= 2.0200018199439707 loss= 0.0022711745303015183\n",
      "训练轮次： 47 w= 2.018134983415867 loss= 0.0018670064049980863\n",
      "训练轮次： 48 w= 2.016442384963719 loss= 0.0015347622429709039\n",
      "训练轮次： 49 w= 2.0149077623671054 loss= 0.0012616427753773154\n",
      "训练轮次： 50 w= 2.0135163712128423 loss= 0.0010371264343723987\n",
      "训练轮次： 51 w= 2.012254843232977 loss= 0.0008525640235623008\n",
      "训练轮次： 52 w= 2.011111057864566 loss= 0.0007008455191026206\n",
      "训练轮次： 53 w= 2.0100740257972065 loss= 0.0005761261653921044\n",
      "训练轮次： 54 w= 2.0091337833894674 loss= 0.00047360131355965045\n",
      "训练轮次： 55 w= 2.0082812969397836 loss= 0.00038932132869331213\n",
      "训练轮次： 56 w= 2.0075083758920704 loss= 0.0003200394353560663\n",
      "训练轮次： 57 w= 2.0068075941421437 loss= 0.000263086639837574\n",
      "训练轮次： 58 w= 2.006172218688877 loss= 0.00021626891068603056\n",
      "训练轮次： 59 w= 2.005596144944582 loss= 0.00017778265653550928\n",
      "训练轮次： 60 w= 2.0050738380830877 loss= 0.0001461452451235924\n",
      "训练轮次： 61 w= 2.0046002798619997 loss= 0.00012013788683582501\n",
      "训练轮次： 62 w= 2.004170920408213 loss= 9.875868244069062e-05\n",
      "训练轮次： 63 w= 2.0037816345034463 loss= 8.118402624102204e-05\n",
      "训练轮次： 64 w= 2.0034286819497913 loss= 6.673687774905789e-05\n",
      "训练轮次： 65 w= 2.0031086716344775 loss= 5.486067959318148e-05\n",
      "训练轮次： 66 w= 2.002818528948593 loss= 4.509791687802551e-05\n",
      "训练轮次： 67 w= 2.0025554662467244 loss= 3.707249202559594e-05\n",
      "训练轮次： 68 w= 2.0023169560636966 loss= 3.047523611135876e-05\n",
      "训练轮次： 69 w= 2.0021007068310848 loss= 2.5051998538471663e-05\n",
      "训练轮次： 70 w= 2.0019046408601837 loss= 2.0593856220775566e-05\n",
      "训练轮次： 71 w= 2.0017268743798997 loss= 1.6929065095977996e-05\n",
      "训练轮次： 72 w= 2.001565699437776 loss= 1.3916443911785405e-05\n",
      "训练轮次： 73 w= 2.00141956749025 loss= 1.1439935404107716e-05\n",
      "训练轮次： 74 w= 2.0012870745244937 loss= 9.404135343749705e-06\n",
      "训练轮次： 75 w= 2.0011669475688745 loss= 7.73061721413683e-06\n",
      "训练轮次： 76 w= 2.001058032462446 loss= 6.354910933009575e-06\n",
      "训练轮次： 77 w= 2.000959282765951 loss= 5.224019227419494e-06\n",
      "训练轮次： 78 w= 2.0008697497077956 loss= 4.294375983569745e-06\n",
      "训练轮次： 79 w= 2.000788573068401 loss= 3.5301679196486234e-06\n",
      "训练轮次： 80 w= 2.0007149729153504 loss= 2.901954926301737e-06\n",
      "训练轮次： 81 w= 2.000648242109918 loss= 2.3855359251949477e-06\n",
      "训练轮次： 82 w= 2.000587739512992 loss= 1.961016554330291e-06\n",
      "训练轮次： 83 w= 2.000532883825113 loss= 1.6120427639495335e-06\n",
      "训练轮次： 84 w= 2.0004831480014356 loss= 1.3251707983126896e-06\n",
      "训练轮次： 85 w= 2.0004380541879683 loss= 1.0893492926917373e-06\n",
      "训练轮次： 86 w= 2.0003971691304248 loss= 8.954935341168123e-07\n",
      "训练轮次： 87 w= 2.000360100011585 loss= 7.361354847576693e-07\n",
      "训练轮次： 88 w= 2.0003264906771703 loss= 6.051360856025233e-07\n",
      "训练轮次： 89 w= 2.0002960182139677 loss= 4.974487573024946e-07\n",
      "训练轮次： 90 w= 2.0002683898473306 loss= 4.0892498733637385e-07\n",
      "训练轮次： 91 w= 2.0002433401282462 loss= 3.3615451403393597e-07\n",
      "训练轮次： 92 w= 2.000220628382943 loss= 2.7633395073593983e-07\n",
      "训练轮次： 93 w= 2.000200036400535 loss= 2.271587890139817e-07\n",
      "训练轮次： 94 w= 2.000181366336485 loss= 1.867346205151668e-07\n",
      "训练轮次： 95 w= 2.0001644388117463 loss= 1.5350415738018074e-07\n",
      "训练轮次： 96 w= 2.0001490911893165 loss= 1.261872397733494e-07\n",
      "训练轮次： 97 w= 2.000135176011647 loss= 1.0373151941523433e-07\n",
      "训练轮次： 98 w= 2.000122559583893 loss= 8.527191924889884e-08\n",
      "训练轮次： 99 w= 2.0001111206893967 loss= 7.009730748565517e-08\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T13:52:04.874349Z",
     "start_time": "2025-01-20T13:52:04.862936Z"
    }
   },
   "cell_type": "code",
   "source": "forword(4)",
   "id": "10854199a58f6a01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.000444482757587"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
