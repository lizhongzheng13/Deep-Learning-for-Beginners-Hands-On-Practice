### 学习与反思

> 主要是记录自己遇到的问题以及踩的坑
> 同时欢迎各位大佬，给我提出意见，我一定会好好吸取。^_^

#### 准确率只有0.1左右？（or 很低）

- 有可能是因为权重没有初始化（不一定是必要的）
- 或者学习率设置的问题，可能设置的太大了，试着调小一些

#### 如何区分验证集和测试集？

![img.png](img.png)

- 训练集 （训练阶段）

> 用于构建我们的模型，我们的模型在训练集上进行学习，通常在这个阶段我们可以有多种方法进行训练

- 验证集 Validation Set（模型挑选阶段）

> 用于挑选最优模型超参的样本集合：使用验证集可以得到反向传播什么时候结束以及超参怎么设置最合理，同时防止过拟合。主要目的是为了挑选在验证集上表现最好的模型。

- 测试集 Test Set（验证阶段 评估泛化误差）

> 在我们挑选好验证集上表现最好的模型之后，用于评估该模型泛化能力的数据集。

#### 如何训练自己的数据集？

1. 首先获取自己的数据，各类数据要相对均衡，以及图片命名尽量不要使用中文
2. 划分训练集和测试集

#### 数据集为什么要进行归一化？

<p>数据归一化（Normalization）是数据预处理中的一个重要步骤，尤其在机器学习和深度学习中。
它将数据缩放到一个统一的范围（通常是 [0, 1] 或 [-1, 1]），从而提高模型的训练效率和性能。</p>
数据归一化是深度学习中不可或缺的步骤，它通过调整数据的范围和分布，帮助模型更快地收敛，减少数值计算问题，提高泛化能力，并简化模型的设计和训练。

#### 图形预处理

1. 尺寸变化
2. 格式转换（变为Tensor格式）
3. 归一化

#### 为什么有时损失函数增加但是精度却在上升？

在训练深度学习模型时，有时会观察到一个看似矛盾的现象：损失函数（Loss）在增加，
但精度（Accuracy）却在上升。这种现象可能由多种原因引起，以下是一些可能的解释：<hr/>

1. 损失函数和精度的衡量方式不同

- **损失函数（Loss）**：衡量的是模型输出与真实标签之间的差异，通常是一个连续的数值。常见的损失函数包括交叉熵损失（Cross-Entropy
  Loss）、均方误差（MSE）等。损失函数越小，表示模型的预测越接近真实值。
- **精度（Accuracy）**：衡量的是模型预测正确的比例，是一个离散的指标。例如，在分类任务中，精度是模型正确分类的样本数占总样本数的比例。
  原因：损失函数和精度的优化目标不同。损失函数关注的是预测值与真实值之间的差异，而精度关注的是预测结果是否完全正确。因此，即使损失函数增加，模型的预测结果可能仍然足够接近真实值，从而导致精度上升。

2. 数据不平衡或类别分布不均

- 如果数据集中某些类别占主导地位，模型可能会偏向于预测这些类别，从而导致损失函数增加，但精度仍然较高。

3. 模型过拟合

- 如果模型在训练集上表现良好，但在验证集上损失函数增加但精度上升，可能是因为模型过拟合了训练集中的某些噪声或异常值。

4. 学习率过高

- 如果学习率设置过高，模型的权重更新可能会过大，导致损失函数在某些迭代中增加。然而，如果模型的预测结果仍然接近真实值，精度可能不会受到影响。

5. 损失函数的选择问题

- 不同的损失函数对误差的敏感度不同。例如，交叉熵损失对概率值的微小变化非常敏感，而精度则只关注最终的分类结果。

6. 数据预处理或数据增强的影响
   -如果在训练过程中使用了数据增强（如随机裁剪、旋转等），模型可能会在某些增强后的数据上表现不佳，导致损失函数增加。但如果这些增强后的数据对精度的影响较小，精度可能仍然较高。

7. 模型架构或正则化的影响

- 如果模型架构过于复杂，或者正则化不足，模型可能会在某些样本上表现不佳，导致损失函数增加。但如果这些样本对精度的影响较小，精度可能仍然较高。

8. 批量大小（Batch Size）的影响

- 如果批量大小设置得过大或过小，可能会导致损失函数和精度之间的不一致。








